{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2ec6a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/grpo/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 05-11 19:10:22 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 19:10:23,333\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from transformers import pipeline\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbeceed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.7: Fast Llama patching. Transformers: 4.51.3. vLLM: 0.8.2.\n",
      "   \\\\   /|    NVIDIA H100 80GB HBM3. Num GPUs = 4. Max memory: 79.19 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 9.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:04<00:00,  1.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(99584, 5120, padding_idx=4)\n",
       "        (layers): ModuleList(\n",
       "          (0-39): 40 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=5120, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=5120, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=5120, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=5120, out_features=5120, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=5120, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=5120, out_features=13824, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=13824, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=5120, out_features=13824, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=13824, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=13824, out_features=5120, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=13824, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=5120, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((5120,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((5120,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((5120,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=5120, out_features=99584, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Replace with your actual model directory\n",
    "model_dir = \"/root/project/GRPO-Ozaki/output/llmjp-grpo-trained/final_model\"\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_dir,\n",
    "    max_seq_length=1024,\n",
    "    load_in_4bit=False,\n",
    "    fast_inference=False,  # 👈 disable fast inference\n",
    ")\n",
    "\n",
    "# Put model in eval mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3311d9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['question_id', 'generated_question', 'answer', 'llm_as_judge_inference', 'llmjp-13b_instruct'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/root/project/GRPO-Ozaki/data/results/answers_ENFP_nemotron_with_results.json\"\n",
    "\n",
    "with open(data_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "data[0].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f18e135f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "更新内容を /root/project/GRPO-Ozaki/data/results/answers_ENFP_nemotron_with_results.json に保存しました。\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "data_path = \"/root/project/GRPO-Ozaki/data/results/answers_ENFP_nemotron_with_results.json\"\n",
    "\n",
    "# JSONファイルを読み込む\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 最初の100件に対して \"Assistant:\" 以降を抽出\n",
    "for i in data[:100]:\n",
    "    full_output = i.get(\"llm_as_judge_inference\", \"\")\n",
    "    match = re.search(r\"Assistant:\\s*(.*)\", full_output, re.DOTALL)\n",
    "    if match:\n",
    "        i[\"llm_as_judge_inference\"] = match.group(1).strip()\n",
    "\n",
    "# 元のファイルに上書き保存する\n",
    "with open(data_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"更新内容を {data_path} に保存しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa15c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: あなたは質問に回答する優秀なアシスタントです.\n",
      "話し方・価値観・思考パターンを反映した、自然かつ一貫性のある回答をして下さい。\n",
      "User: 持続可能な生活に関心がある場合、具体的な行動計画を立てることを重視しますか、それとも環境への影響について広範な認識を持つことを優先しますか？\n",
      "\n",
      "Assistant: 私は持続可能な生活へのアプローチとして、両方の側面が重要だと考えています。まず、環境への影響について広範な認識を持つことは、持続可能な生活を実現するための基盤となります。これにより、日常の行動が地球環境にどのような影響を与えるのかを理解し、その影響を最小限に抑えるための具体的な行動を計画することが可能になります。例えば、エネルギーの使用効率を高めることや、リサイクルの習慣を身につけること、そして持続可能な製品を選ぶことなどが挙げられます。\n",
      "\n",
      "ただし、広範な認識だけでは不十分で、具体的な行動計画がなければ持続可能な生活の実現は難しいでしょう。行動計画を立てる際には、短期的および長期的な目標を設定し、それを達成するためのステップを明確にすることが重要です。また、定期的に進捗を評価し、必要に応じて計画を修正することも求められます。\n",
      "\n",
      "したがって、私は環境への影響についての広範な認識を持ちつつ、それに基づいた具体的な行動計画を立てることが最も効果的なアプローチだと考えています。このバランスが取れたアプローチにより、持続可能な生活をより効果的に実現できるでしょう。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "system_prompt = \\\n",
    "f\"\"\"あなたは質問に回答する優秀なアシスタントです.\n",
    "話し方・価値観・思考パターンを反映した、自然かつ一貫性のある回答をして下さい。\"\"\"\n",
    "\n",
    "def build_prompt(messages):\n",
    "    return \"\\n\".join([f\"{m['role'].capitalize()}: {m['content']}\" for m in messages])\n",
    "\n",
    "def infer(question: str):\n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ]\n",
    "\n",
    "    input_text = build_prompt(prompt)\n",
    "\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=500,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        pad_token_id=tokenizer.eos_token_id,  # just in case\n",
    "    )\n",
    "\n",
    "    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return output_text\n",
    "\n",
    "# Example\n",
    "prediction =  infer(data[0][\"generated_question\"])\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "baf9c4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'私が答える前に、自分の性格タイプを再確認してみましょう。\\n\\n*   自由奔放で社交的\\n*   情熱的で創造的\\n*   直感を重視し、人生の深い意味や目的を探求\\n*   自立心が強く、興味を持ったことには夢中になる\\n*   感受性が高く、他者の気持ちに共感\\n\\n持続可能な生活に関心がある場合、具体的な行動計画を立てることと環境への影響について広範な認識を持つことの両方は重要ですが、私の性格タイプに基づいて優先順位を付けるなら、**環境への影響について広範な認識を持つことを優先します**。その理由は以下の通りです。\\n\\n1.  **直感と創造性の活用**：広範な認識を優先することで、私の直感と創造性を活用して、持続可能な生活のより広い視点を把握できます。環境への影響を理解することで、革新的な解決策を見出すきっかけを得られます。\\n2.  **深い意味や目的の探求**：環境への影響についての認識は、持続可能な生活の本質と人生におけるその意味をより深く理解するのに役立ちます。持続可能な生活が私自身や社会、地球に与える影響を考えることで、生活に深い目的意識を感じることができます。\\n3.  **感受性と共感**：環境への影響を理解することで、自然や他の生き物とのつながりを深めることができます。これは、私の感受性と共感を高め、持続可能な生活への関心をさらに強めることにつながります。\\n4.  **自立心と情熱**：広範な認識を得た後、自立心を活かし、自分の生活スタイルに合わせた具体的な行動計画を立てることができます。環境への影響を理解していることで、行動の重要性をより強く感じ、持続可能な生活への情熱が持続します。\\n\\n具体的な行動計画も重要ですが、私の性格タイプに合わせると、まずは環境への影響についての認識を深めることで、創造的にかつ情熱を持って持続可能な生活を送る基盤を作りたいと思います。そうすることで、自然な流れで自立心を活かし、具体的な行動計画を立てるようになるでしょう。'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66fa911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/grpo/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Generating train split: 100%|██████████| 50/50 [00:00<00:00, 7679.34 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"DeL-TaiseiOzaki/50_mbti_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62da6fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': 1,\n",
       " 'question_text': '社会的な集まりでは、大人数と交流するほうがエネルギーを得られますか、それとも1対1で話すほうがエネルギーを得られますか？',\n",
       " 'option_a': {'text': '大人数と交流する', 'trait': 'E'},\n",
       " 'option_b': {'text': '1対1で話す', 'trait': 'I'}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c843b471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grpo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
